# Your AI for CTF must inherit from the base Commander class.  See how this is
# implemented by looking at the commander.py in the ./api/ folder.
from api import Commander

# The commander can send 'Commands' to individual bots.  These are listed and
# documented in commands.py from the ./api/ folder also.
from api import commands

# The maps for CTF are layed out along the X and Z axis in space, but can be
# effectively be considered 2D.
from api import Vector2

import pickle, os, inspect, random, datetime
import pythonDbHandler, regressions


class learningCommander(Commander):
    """
    Rename and modify this class to create your own commander and add mycmd.Placeholder
    to the execution command you use to run the competition.
    """ 
    def initialFeatureGenerator(self):
        features = {}
        features['enemyFlag'] = self.game.enemyTeam.flag.position
        return features
                 
    def classifierGenerator(self):
        test = False
        if test == True:
            if self.game.team.name == 'Red':
                classifier = pythonDbHandler.loadClassifier(52)
            else:
                classifier = pythonDbHandler.loadClassifier(53)
            return classifier
        
        elif 'red_team_bot_id' in os.environ:
            if self.game.team.name == 'Red':
                botID = int(os.environ['red_team_bot_id'])
                classifier = pythonDbHandler.loadClassifier(botID)
            elif self.game.team.name == 'Blue':
                botID = int(os.environ['blue_team_bot_id'])
                classifier = pythonDbHandler.loadClassifier(botID)
            if classifier != None:
                self.botID = botID
                return classifier 
        else:
            classifier = {
            commands.Attack : [[regressions.enemyFlag, 1],
                               [regressions.timeToScore, 1],
                               [regressions.lookTowardEnemyBots, -1],
                               [regressions.spread, -1],
                               [regressions.lookTowardEnemyBase, -1]
                               ],
            'currentAction' : [[regressions.botsInSightCone, 1]
                               ],
            commands.Charge : [[regressions.botsInSightCone, 1],
                               [regressions.canEnemyBotSeePath, -1],
                               [regressions.timeToScore, 5]
                               ],
            commands.Move : [[regressions.enemyFlag, 1],
                             [regressions.botsInSightCone, 1],
                             [regressions.canEnemyBotSeePath, -1],
                             [regressions.timeToScore, 5]
                             ],
            commands.Defend : [[regressions.enemyFlag, 1],
                              [regressions.botsInSightCone, 1]
                              ]
                        }
            return classifier

    def initialize(self):
        """Use this function to setup your bot before the game starts."""
        if 'blue_team_bot_id' in os.environ:
            print 'BLUE TEAM BOT ID IN AUTOCMD: ', os.environ['blue_team_bot_id']
            print 'BLUE TEAM BOT ID IN AUTOCMD: ', os.environ['red_team_bot_id'] 
        self.verbose = True    # display the command descriptions next to the bot labels
        self.counter = 0
        self.randomRate = 0.0
        self.bots = {}
        self.learningRate = .05
        self.discount = 0.0
        for bot in self.game.team.members:
            self.bots[bot] = {'currentAction': None, 'storedRegressionVector' : None,
                             'storedRegressionValueVector': None, 'forecastedValue' : None, 'timeOfAction': 0.0,
                              'dead': False, 'latest_event_processed': 0.0
                              }
        # Classifier: Structured as {commands.Attack : (regression0, coefficient0), (regression1, coefficient1}... commands.Defend : (regression0.....)}
        self.actionClassifier = self.classifierGenerator()
        # Store all needed features.
        self.features = self.initialFeatureGenerator()
        
    def tick(self):
        """Routine to deal with new information every interval of about .1s"""
        self.counter += 1
        for bot in self.game.team.members:
            #Decide if that bot's action is done or it has died and update the weight vector accordingly/issue a new action.
            resolved = self.testForActionResolved(bot)
            if resolved == 'died':
                legalActions = self.getCandidateActions(bot)
                presentBestActionValue = self.getPolicy(bot, legalActions)[1]
                reward = self.getReward(bot)
##                self.updateWeights(bot, reward, presentBestActionValue)
                self.resetCurrentBotInfo(bot)
                continue
            elif resolved == 'finished':
                legalActions = self.getCandidateActions(bot)
                (action, value, regressionVector, regressionValueVector) = self.getAction(bot, legalActions)
                presentBestActionValue = self.getPolicy(bot, legalActions)[1]
                reward = self.getReward(bot)
##                self.updateWeights(bot, reward, presentBestActionValue)
                self.issueAndStore(action, value, regressionVector, regressionValueVector)
                continue
            #Every x ticks, check all bots for better commands than their current ones.
            elif self.counter % 50 == 0:
                legalActions = self.getCandidateActions(bot)
                (action, value, regressionVector, regressionValueVector) = self.getAction(bot, legalActions)
                if bot.health > 0:
                    reward = self.getReward(bot)
                    presentBestActionValue = self.getPolicy(bot, legalActions)[1]       
##                    self.updateWeights(bot, reward, presentBestActionValue = self.getPolicy(bot, legalActions)[1])
                self.issueAndStore(action, value, regressionVector, regressionValueVector)

    def resetCurrentBotInfo(self, bot):
        self.bots[bot]['currentAction'] = None
        self.bots[bot]['storedRegressionVector'] = None
        self.bots[bot]['storedRegressionValueVector'] = None
        self.bots[bot]['forecastedValue'] = None,
        self.bots[bot]['timeOfAction'] = 0.0
                
    def updateWeights(self, bot, reward, presentBestActionValue):
        """Iterate over the weights used in the bot's last action, updating based on expected returns vs actual."""
        #If the currentAction is None, no action has yet been issued and there is no information to update. This happens early in games.
        if self.bots[bot]['currentAction'] == None:
            return
        
        command = self.bots[bot]['currentAction'][0]
        oldRegressions = self.bots[bot]['storedRegressionVector']
        regressions = self.actionClassifier[command]
        storedValueVector = self.bots[bot]['storedRegressionValueVector']
        forecastedValue = self.bots[bot]['forecastedValue']

        printedUpdateList = []
        
        legalActions = self.getCandidateActions(bot) 
        for index in range(len(regressions)):
            #Updating weights requires checking to see if the update we want to make has already been made by another bot.
            #We don't want to get the same update twice.
            oldWeight = oldRegressions[index][1]
            actualCurrentWeight = regressions[index][1]
            featureValue = storedValueVector[index]
            
            proposedNewWeight = \
            oldWeight + self.learningRate*featureValue*(reward + self.discount*presentBestActionValue - forecastedValue)

            proposedChange = proposedNewWeight - oldWeight
            changeFromOtherActionsBetweenCommandAndUpdate = actualCurrentWeight - oldWeight
            
            printedUpdateList.append(proposedChange)
            
            if proposedChange != 0.0:
                if changeFromOtherActionsBetweenCommandAndUpdate/proposedChange > 0.0:
                    continue
                else:
                    regressions[index][1] = proposedNewWeight
        print
        print ' bot: ', bot
        print ' reward: ', reward
        print ' change: ', proposedChange
        print ' weights list: ', [weight[1] for weight in self.actionClassifier[commands.Attack]]
        print ' update changes: ', printedUpdateList
        
    def getReward(self, bot):
        """Calculates how a finished action turned out for our bot. TODO learn reward values as opposed to hard? """
        killed = 1
        flagPickedUp = 2
        flagDropped = 3
        flagCaptured = 4
        flagRestored = 5
        botRespawned = 6        
        reward = 0
        #Only count events we have not counted yet.
        for event in self.game.match.combatEvents:
            if event.time > self.bots[bot]['latest_event_processed']:
                self.bots[bot]['latest_event_processed'] = event.time
                if event.subject == bot or event.instigator == bot:
                    #Did the bot die or kill something since it last committed to an action?
                    if event.type == killed:
                        if event.subject == bot:
                            reward -= .5
                        elif event.instigator == bot:
                            reward += .6
                    elif event.type == flagPickedUp:
                        if event.instigator == bot:
                            reward += 2
                    elif event.type == flagCaptured:
                        if event.instigator == bot:
                            reward += 4
                    print 'event: ', event.type, '    bot: ', bot 
        return reward

    def testForActionResolved(self, bot):
        """Check if a given bot has either finished its action or died recently. Return True if yes, False if otherwise.
        This is used to tell when we update our weights, and when we give new orders out of cycle.
        """
        killed = 1
        respawned = 6
        #Check if the bot has respawned and hence needs new orders
        for event in self.game.match.combatEvents:
            if event.time > self.bots[bot]['latest_event_processed'] and event.type == respawned:
                self.bots[bot]['dead'] == False
                self.bots[bot]['latest_event_processed'] = event.time
        #Check if bot needs to be set to dead, or if it has finished an order. 
        if self.bots[bot]['dead'] == False or bot.health > 0:
            for event in self.game.match.combatEvents:
                #Did the bot die since it last committed to an action?
                if event.type == killed and self.bots[bot]['timeOfAction'] < event.time and event.subject == bot and bot.health < 0:
                    self.bots[bot]['dead'] = True
                    return 'died'
            if bot in self.game.bots_available:
                return 'finished'
            else:
                return False
        elif self.bots[bot]['dead'] == True:
            return False
 
    def getAction(self, bot, legalActions):
        """
          Implements picking an action for a bot, allows for epsilon greedy exploration to be coded in.
          Returns value for issueAndStore to store for use in update function.
        """
        #Pick action either by exploring a random available option at a predetermined rate, or choosing amongst the best available options.
##        if len(legalActions) == 0:
##            (action, value, regressionVector, regressionValueVector) = (None, None, None, None)
##        elif random.random() < self.randomRate == True:
##            (action, value, regressionVector, regressionValueVector) = (random.choice(legalActions), None, None, None)
##        else:
        (action, value, regressionVector, regressionValueVector)  = self.getPolicy(bot, legalActions)
        legalActions = self.getLookDirectionArray(15, action)
        (action, value, regressionVector, regressionValueVector) = self.getPolicy(bot, legalActions)
        return (action, value, regressionVector, regressionValueVector)
        
    def getPolicy(self, bot, candidateActions):
        """
          Compute the best action to take for a given bot by getting all values, choosing highest.
          Return action, valuation of action, regression vector used to get valuation.
        """
        if len(candidateActions) == 0:
            print 'WARNING: EMPTY CANDIDATE ACTION LIST. FIX THAT FUNCTION!'
            return (None, None, None)
        bestAction = None
        bestValue = float("-inf")
        bestSet = []
        bestRegressionVector = None
        for action in candidateActions:
            (value, regressionVector, regressionValueVector) = self.getHueristicValue(bot, action)
            if value == bestValue:
                bestSet.append((action, value, regressionVector, regressionValueVector)) 
            elif value > bestValue:
                bestValue = value
                bestAction = action
                bestSet = []
                bestRegressionVector = regressionVector
                bestRegressionValueVector = regressionValueVector         
        if len(bestSet) != 0:
            return random.choice(bestSet)
        return (bestAction, bestValue, bestRegressionVector, bestRegressionValueVector)

    def getCandidateActions(self, state):#TODO, random map filter, generate new points about best N actions, pick best from secondary filter.
        """Use random distribution across map to find potential points, add current action, defend facing a random set of directions.
        Alongside projected action by doing nothing."""
        bot = state
        actions = []
        for x in range(100):
            lookAtDirection = self.level.findRandomFreePositionInBox(self.level.area) 
            defendDirection = Vector2(random.random()*random.sample([-1,1],1)[0], random.random()*random.sample([-1,1],1)[0])
            position = self.level.findRandomFreePositionInBox(self.level.area)         
            #Add random attack positions.
            actions.append([commands.Attack, bot, [position], lookAtDirection, "Attacking selected point."])
##            #Add defend commands with random directions.
##            actions.append([commands.Defend, bot, defendDirection, "Defending facing random direction."])
            #Add random move commands.
##            actions.append([commands.Move, bot, position, "Moving to selected point."])
            #Add random charge commands.
##            actions.append([commands.Charge, bot, position, "Charging to selected point."])            
        #Add current action string as an option. Parsed to special action that continues to execute current command.
##        actions.append(['currentAction'])
        return actions

    def getLookDirectionArray(self, numActions, action):
        """Returns an arbitrary length list of actions based on the passed action with random look directions."""
        newActionList = []
        if action[0] == commands.Attack:
            for x in range(numActions):
                lookAtDirection = self.level.findRandomFreePositionInBox(self.level.area)
                action[3] = lookAtDirection
                newActionList.append(action)
        elif action[0] == commands.Defend:
            for x in range(numActions):
                defendDirection = Vector2(random.random()*random.sample([-1,1],1)[0], random.random()*random.sample([-1,1],1)[0])
                action[3] = lookAtDirection
                newActionList.append(action)
        return newActionList

    def getHueristicValue(self, bot, action):
        #Takes bot, action, uses self.classifier dict to return a valuation of the bot's action.
        command = action[0]
        value = 0
        regressionVector = self.actionClassifier[command]
        regressionValueVector = []
        for functionAndWeightPair in regressionVector:
            featureValue = functionAndWeightPair[0](self, bot, action)
            regressionValueVector.append(featureValue)
            weight = functionAndWeightPair[1]
            singleFunctionValue = featureValue * weight
            value += singleFunctionValue
        return (value, regressionVector, regressionValueVector)
        
    def issueAndStore(self, action, value, regressionVector, regressionValueVector):
        """Takes a list that constitutes a stored action, decides what kind of action it is,
        issues that command, tells commander bot is doing that command. We do this rather than directly
        issue so that currentAction can be a candidateAction."""        
        command = action[0]
        if command == 'currentAction':
            #Doing nothing continues current action. This is explicitly included for conceptual simplicity.
            return
        bot = action[1]
        if command == commands.Attack:
            self.issue(command, bot, action[2], action[3], description = action[4])
        elif command == commands.Defend:
            self.issue(command, bot, facingDirection = action[2], description=action[3])
        elif command == commands.Charge:
            self.issue(command, bot, action[2], description = action[3])
        elif command == commands.Move:
            self.issue(command, bot, action[2], description = action[3])            
        #Stores the action as the bots currently executing action.
        #Also store the regressions dict that picked it, the calculated value of the chosen action, and its time. 
        self.bots[bot]['currentAction'] = action
        self.bots[bot]['forecastedValue'] = value
        self.bots[bot]['storedRegressionVector'] = regressionVector
        self.bots[bot]['timeOfAction'] = self.game.match.timePassed
        self.bots[bot]['storedRegressionValueVector'] = regressionValueVector

    def shutdown(self):
        """Use this function to teardown your bot after the game is over, or perform an
        analysis of the data accumulated during the game."""
        print 'SHUTTING DOWN AND STORING'
        pythonDbHandler.storeClassifier(self.actionClassifier, self.botID)
